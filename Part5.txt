
BLEU Scores

BLEU scores separated by the alignment model # of training sentences (1K, 10K, 15K, 30K)
Each line represents a triplet of: 
-- the sentence number in /u/cs401/A2 SMT/data/Hansard/Testing/Task5.f
-- the n-value passed to calculate the BLEU score
-- the resultant BLEU score 
in that order, with each value separated by a space.


We can see the difference in the references based on their BLEU scores. 
Our scores on the Task5.e (Hansard) reference is generally better than on the Google translations. This is expected since we developed our model based on Hansard data.
We can assume that Google Translate has a different language model leading to the difference in results from the two references.


We would expect that using more references leads to better performance.
This is because the evaluation model should be able to better generalize the meaning of sentences, as opposed to focusing on the particular order of n-grams during decoding.
In other words, by using more reference we can prevent overfitting our machine translation model to one particular translation set.


=================================================


1000 sentences


/u/cs401/A2_SMT/data/Hansard/Testing/Task5.e sentences


1 1 0.07692307692307693
1 2 0.0
1 3 0.0
2 1 0.09090909090909091
2 2 0.0
2 3 0.0
3 1 0.11764705882352941
3 2 0.0
3 3 0.0
4 1 0.07142857142857142
4 2 0.0
4 3 0.0
5 1 0.08333333333333333
5 2 0.0
5 3 0.0
6 1 0.0
6 2 0.0
6 3 0.0
7 1 0.1
7 2 0.0
7 3 0.0
8 1 0.25
8 2 0.0
8 3 0.0
9 1 0.0
9 2 0.0
9 3 0.0
10 1 0.0
10 2 0.0
10 3 0.0
11 1 0.0
11 2 0.0
11 3 0.0
12 1 0.1
12 2 0.0
12 3 0.0
13 1 0.1111111111111111
13 2 0.0
13 3 0.0
14 1 0.07142857142857142
14 2 0.0
14 3 0.0
15 1 0.06666666666666667
15 2 0.0
15 3 0.0
16 1 0.15384615384615385
16 2 0.0
16 3 0.0
17 1 0.07692307692307693
17 2 0.0
17 3 0.0
18 1 0.0625
18 2 0.0
18 3 0.0
19 1 0.18181818181818182
19 2 0.0
19 3 0.0
20 1 0.14285714285714285
20 2 0.0
20 3 0.0
21 1 0.25
21 2 0.0
21 3 0.0
22 1 0.1
22 2 0.0
22 3 0.0
23 1 0.1875
23 2 0.0
23 3 0.0
24 1 0.13333333333333333
24 2 0.0
24 3 0.0
25 1 0.14285714285714285
25 2 0.0
25 3 0.0


/u/cs401/A2_SMT/data/Hansard/Testing/Task5.google.e sentences


1 1 0.14285714285714285
1 2 0.0
1 3 0.0
2 1 0.125
2 2 0.0
2 3 0.0
3 1 0.2727272727272727
3 2 0.0
3 3 0.0
4 1 0.09090909090909091
4 2 0.0
4 3 0.0
5 1 0.07692307692307693
5 2 0.0
5 3 0.0
6 1 0.25
6 2 0.0
6 3 0.0
7 1 0.16666666666666666
7 2 0.0
7 3 0.0
8 1 0.25
8 2 0.0
8 3 0.0
9 1 0.0
9 2 0.0
9 3 0.0
10 1 0.125
10 2 0.0
10 3 0.0
11 1 0.0
11 2 0.0
11 3 0.0
12 1 0.1
12 2 0.0
12 3 0.0
13 1 0.09090909090909091
13 2 0.0
13 3 0.0
14 1 0.07692307692307693
14 2 0.0
14 3 0.0
15 1 0.125
15 2 0.0
15 3 0.0
16 1 0.09090909090909091
16 2 0.0
16 3 0.0
17 1 0.125
17 2 0.0
17 3 0.0
18 1 0.1
18 2 0.0
18 3 0.0
19 1 0.18181818181818182
19 2 0.0
19 3 0.0
20 1 0.09090909090909091
20 2 0.0
20 3 0.0
21 1 0.25
21 2 0.0
21 3 0.0
22 1 0.09090909090909091
22 2 0.0
22 3 0.0
23 1 0.14285714285714285
23 2 0.0
23 3 0.0
24 1 0.14285714285714285
24 2 0.0
24 3 0.0
25 1 0.14285714285714285
25 2 0.0
25 3 0.0


10000 sentences




/u/cs401/A2_SMT/data/Hansard/Testing/Task5.e sentences


1 1 0.07692307692307693
1 2 0.0
1 3 0.0
2 1 0.09090909090909091
2 2 0.0
2 3 0.0
3 1 0.11764705882352941
3 2 0.0
3 3 0.0
4 1 0.07142857142857142
4 2 0.0
4 3 0.0
5 1 0.08333333333333333
5 2 0.0
5 3 0.0
6 1 0.0
6 2 0.0
6 3 0.0
7 1 0.1
7 2 0.0
7 3 0.0
8 1 0.25
8 2 0.0
8 3 0.0
9 1 0.0
9 2 0.0
9 3 0.0
10 1 0.0
10 2 0.0
10 3 0.0
11 1 0.0
11 2 0.0
11 3 0.0
12 1 0.1
12 2 0.0
12 3 0.0
13 1 0.1111111111111111
13 2 0.0
13 3 0.0
14 1 0.07142857142857142
14 2 0.0
14 3 0.0
15 1 0.06666666666666667
15 2 0.0
15 3 0.0
16 1 0.15384615384615385
16 2 0.0
16 3 0.0
17 1 0.07692307692307693
17 2 0.0
17 3 0.0
18 1 0.0625
18 2 0.0
18 3 0.0
19 1 0.18181818181818182
19 2 0.0
19 3 0.0
20 1 0.14285714285714285
20 2 0.0
20 3 0.0
21 1 0.25
21 2 0.0
21 3 0.0
22 1 0.1
22 2 0.0
22 3 0.0
23 1 0.1875
23 2 0.0
23 3 0.0
24 1 0.13333333333333333
24 2 0.0
24 3 0.0
25 1 0.14285714285714285
25 2 0.0
25 3 0.0


/u/cs401/A2_SMT/data/Hansard/Testing/Task5.google.e sentences


1 1 0.14285714285714285
1 2 0.0
1 3 0.0
2 1 0.125
2 2 0.0
2 3 0.0
3 1 0.2727272727272727
3 2 0.0
3 3 0.0
4 1 0.09090909090909091
4 2 0.0
4 3 0.0
5 1 0.07692307692307693
5 2 0.0
5 3 0.0
6 1 0.25
6 2 0.0
6 3 0.0
7 1 0.16666666666666666
7 2 0.0
7 3 0.0
8 1 0.25
8 2 0.0
8 3 0.0
9 1 0.0
9 2 0.0
9 3 0.0
10 1 0.125
10 2 0.0
10 3 0.0
11 1 0.0
11 2 0.0
11 3 0.0
12 1 0.1
12 2 0.0
12 3 0.0
13 1 0.09090909090909091
13 2 0.0
13 3 0.0
14 1 0.07692307692307693
14 2 0.0
14 3 0.0
15 1 0.125
15 2 0.0
15 3 0.0
16 1 0.09090909090909091
16 2 0.0
16 3 0.0
17 1 0.125
17 2 0.0
17 3 0.0
18 1 0.1
18 2 0.0
18 3 0.0
19 1 0.18181818181818182
19 2 0.0
19 3 0.0
20 1 0.09090909090909091
20 2 0.0
20 3 0.0
21 1 0.25
21 2 0.0
21 3 0.0
22 1 0.09090909090909091
22 2 0.0
22 3 0.0
23 1 0.14285714285714285
23 2 0.0
23 3 0.0
24 1 0.14285714285714285
24 2 0.0
24 3 0.0
25 1 0.14285714285714285
25 2 0.0
25 3 0.0


15000 sentences




/u/cs401/A2_SMT/data/Hansard/Testing/Task5.e sentences


1 1 0.07692307692307693
1 2 0.0
1 3 0.0
2 1 0.09090909090909091
2 2 0.0
2 3 0.0
3 1 0.11764705882352941
3 2 0.0
3 3 0.0
4 1 0.07142857142857142
4 2 0.0
4 3 0.0
5 1 0.08333333333333333
5 2 0.0
5 3 0.0
6 1 0.0
6 2 0.0
6 3 0.0
7 1 0.1
7 2 0.0
7 3 0.0
8 1 0.25
8 2 0.0
8 3 0.0
9 1 0.0
9 2 0.0
9 3 0.0
10 1 0.0
10 2 0.0
10 3 0.0
11 1 0.0
11 2 0.0
11 3 0.0
12 1 0.1
12 2 0.0
12 3 0.0
13 1 0.1111111111111111
13 2 0.0
13 3 0.0
14 1 0.07142857142857142
14 2 0.0
14 3 0.0
15 1 0.06666666666666667
15 2 0.0
15 3 0.0
16 1 0.15384615384615385
16 2 0.0
16 3 0.0
17 1 0.07692307692307693
17 2 0.0
17 3 0.0
18 1 0.0625
18 2 0.0
18 3 0.0
19 1 0.18181818181818182
19 2 0.0
19 3 0.0
20 1 0.14285714285714285
20 2 0.0
20 3 0.0
21 1 0.25
21 2 0.0
21 3 0.0
22 1 0.1
22 2 0.0
22 3 0.0
23 1 0.1875
23 2 0.0
23 3 0.0
24 1 0.13333333333333333
24 2 0.0
24 3 0.0
25 1 0.14285714285714285
25 2 0.0
25 3 0.0


/u/cs401/A2_SMT/data/Hansard/Testing/Task5.google.e sentences


1 1 0.14285714285714285
1 2 0.0
1 3 0.0
2 1 0.125
2 2 0.0
2 3 0.0
3 1 0.2727272727272727
3 2 0.0
3 3 0.0
4 1 0.09090909090909091
4 2 0.0
4 3 0.0
5 1 0.07692307692307693
5 2 0.0
5 3 0.0
6 1 0.25
6 2 0.0
6 3 0.0
7 1 0.16666666666666666
7 2 0.0
7 3 0.0
8 1 0.25
8 2 0.0
8 3 0.0
9 1 0.0
9 2 0.0
9 3 0.0
10 1 0.125
10 2 0.0
10 3 0.0
11 1 0.0
11 2 0.0
11 3 0.0
12 1 0.1
12 2 0.0
12 3 0.0
13 1 0.09090909090909091
13 2 0.0
13 3 0.0
14 1 0.07692307692307693
14 2 0.0
14 3 0.0
15 1 0.125
15 2 0.0
15 3 0.0
16 1 0.09090909090909091
16 2 0.0
16 3 0.0
17 1 0.125
17 2 0.0
17 3 0.0
18 1 0.1
18 2 0.0
18 3 0.0
19 1 0.18181818181818182
19 2 0.0
19 3 0.0
20 1 0.09090909090909091
20 2 0.0
20 3 0.0
21 1 0.25
21 2 0.0
21 3 0.0
22 1 0.09090909090909091
22 2 0.0
22 3 0.0
23 1 0.14285714285714285
23 2 0.0
23 3 0.0
24 1 0.14285714285714285
24 2 0.0
24 3 0.0
25 1 0.14285714285714285
25 2 0.0
25 3 0.0


30000 sentences




/u/cs401/A2_SMT/data/Hansard/Testing/Task5.e sentences


1 1 0.07692307692307693
1 2 0.0
1 3 0.0
2 1 0.09090909090909091
2 2 0.0
2 3 0.0
3 1 0.11764705882352941
3 2 0.0
3 3 0.0
4 1 0.07142857142857142
4 2 0.0
4 3 0.0
5 1 0.08333333333333333
5 2 0.0
5 3 0.0
6 1 0.0
6 2 0.0
6 3 0.0
7 1 0.1
7 2 0.0
7 3 0.0
8 1 0.25
8 2 0.0
8 3 0.0
9 1 0.1111111111111111
9 2 0.0
9 3 0.0
10 1 0.0
10 2 0.0
10 3 0.0
11 1 0.0
11 2 0.0
11 3 0.0
12 1 0.1
12 2 0.0
12 3 0.0
13 1 0.1111111111111111
13 2 0.0
13 3 0.0
14 1 0.07142857142857142
14 2 0.0
14 3 0.0
15 1 0.06666666666666667
15 2 0.0
15 3 0.0
16 1 0.15384615384615385
16 2 0.0
16 3 0.0
17 1 0.07692307692307693
17 2 0.0
17 3 0.0
18 1 0.0625
18 2 0.0
18 3 0.0
19 1 0.18181818181818182
19 2 0.0
19 3 0.0
20 1 0.14285714285714285
20 2 0.0
20 3 0.0
21 1 0.25
21 2 0.0
21 3 0.0
22 1 0.1
22 2 0.0
22 3 0.0
23 1 0.1875
23 2 0.0
23 3 0.0
24 1 0.13333333333333333
24 2 0.0
24 3 0.0
25 1 0.14285714285714285
25 2 0.0
25 3 0.0


/u/cs401/A2_SMT/data/Hansard/Testing/Task5.google.e sentences


1 1 0.14285714285714285
1 2 0.0
1 3 0.0
2 1 0.125
2 2 0.0
2 3 0.0
3 1 0.18181818181818182
3 2 0.0
3 3 0.0
4 1 0.09090909090909091
4 2 0.0
4 3 0.0
5 1 0.07692307692307693
5 2 0.0
5 3 0.0
6 1 0.25
6 2 0.0
6 3 0.0
7 1 0.16666666666666666
7 2 0.0
7 3 0.0
8 1 0.25
8 2 0.0
8 3 0.0
9 1 0.0
9 2 0.0
9 3 0.0
10 1 0.125
10 2 0.0
10 3 0.0
11 1 0.0
11 2 0.0
11 3 0.0
12 1 0.1
12 2 0.0
12 3 0.0
13 1 0.09090909090909091
13 2 0.0
13 3 0.0
14 1 0.07692307692307693
14 2 0.0
14 3 0.0
15 1 0.125
15 2 0.0
15 3 0.0
16 1 0.09090909090909091
16 2 0.0
16 3 0.0
17 1 0.125
17 2 0.0
17 3 0.0
18 1 0.1
18 2 0.0
18 3 0.0
19 1 0.18181818181818182
19 2 0.0
19 3 0.0
20 1 0.09090909090909091
20 2 0.0
20 3 0.0
21 1 0.25
21 2 0.0
21 3 0.0
22 1 0.09090909090909091
22 2 0.0
22 3 0.0
23 1 0.14285714285714285
23 2 0.0
23 3 0.0
24 1 0.14285714285714285
24 2 0.0
24 3 0.0
25 1 0.14285714285714285
25 2 0.0
25 3 0.0
